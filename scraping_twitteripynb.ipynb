{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "scraping_twitteripynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "173UBmsd4icOiw-4fk5U1VuvZWSzL0ZTF",
      "authorship_tag": "ABX9TyPjGtH2Da/og0/ORUGkgfFs",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Naomiweinberger/Hate-Speech/blob/main/scraping_twitteripynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbGN-MAjGgF6",
        "outputId": "bf7a5d1c-5d61-4e44-c8b5-e99482e31c76"
      },
      "source": [
        "! pip install twitter-to-sqlite"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: twitter-to-sqlite in /usr/local/lib/python3.7/dist-packages (0.22)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from twitter-to-sqlite) (2.8.2)\n",
            "Requirement already satisfied: requests-oauthlib~=1.2.0 in /usr/local/lib/python3.7/dist-packages (from twitter-to-sqlite) (1.2.0)\n",
            "Requirement already satisfied: sqlite-utils>=2.4.2 in /usr/local/lib/python3.7/dist-packages (from twitter-to-sqlite) (3.17.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib~=1.2.0->twitter-to-sqlite) (3.1.1)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib~=1.2.0->twitter-to-sqlite) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->requests-oauthlib~=1.2.0->twitter-to-sqlite) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->requests-oauthlib~=1.2.0->twitter-to-sqlite) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->requests-oauthlib~=1.2.0->twitter-to-sqlite) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->requests-oauthlib~=1.2.0->twitter-to-sqlite) (2021.5.30)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sqlite-utils>=2.4.2->twitter-to-sqlite) (7.1.2)\n",
            "Requirement already satisfied: sqlite-fts4 in /usr/local/lib/python3.7/dist-packages (from sqlite-utils>=2.4.2->twitter-to-sqlite) (1.0.1)\n",
            "Requirement already satisfied: dateutils in /usr/local/lib/python3.7/dist-packages (from sqlite-utils>=2.4.2->twitter-to-sqlite) (0.6.12)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from sqlite-utils>=2.4.2->twitter-to-sqlite) (0.8.9)\n",
            "Requirement already satisfied: click-default-group in /usr/local/lib/python3.7/dist-packages (from sqlite-utils>=2.4.2->twitter-to-sqlite) (1.2.2)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from dateutils->sqlite-utils>=2.4.2->twitter-to-sqlite) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil->twitter-to-sqlite) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OL9FTCfxJFYl"
      },
      "source": [
        "import tweepy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os, csv, logging, urllib, urllib3, json,bson, re,string\n",
        "from bson import json_util\n",
        "from datetime import datetime, timedelta\n",
        "from datetime import time\n",
        "import collections ,sys,math, time, datetime\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWITTGP0Qhlg"
      },
      "source": [
        "CONSUMER_TOKEN='TnmcLLxDlHxtJA0QJ0WvgWqLg'\n",
        "CONSUMER_SECRET='PhW4yLG40E5z4j7iJQlVMOgplt9XUFMnHW0f35xdBa4nw88zbZ'\n",
        "access_token ='3434213404-jLN4nHB721dYxUsOrvad4JktymCAWVSxqtgaw7t'\n",
        "access_token_secret='pnfsXc3lePJwJ4Mk0J9kxLJfJTZPC2CJ9wNjVuDHqXQ5m'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLRnCMxeM18Y"
      },
      "source": [
        "auth  = tweepy.OAuthHandler(CONSUMER_TOKEN, \\\n",
        "                            CONSUMER_SECRET)\n",
        "auth.set_access_token(access_token,  \\\n",
        "                      access_token_secret)\n",
        "api = tweepy.API(auth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDOgiDdn9hgw"
      },
      "source": [
        "**normal** **tweets**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kOqwYcyTsYd"
      },
      "source": [
        "tweets_normal = api.search('Artificial Intelligence', count=20)\n",
        "normal_tweet=[]\n",
        "for tweet in tweets_normal:\n",
        "  normal_tweet.append(tweet.text)\n",
        "df_normal = pd.DataFrame(tweets_normal)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U23hSfHn95IS"
      },
      "source": [
        "df_normal['tweet']=df_normal\n",
        "df_normal['label']=2\n",
        "df_normal=df_normal[['tweet','label']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_TOKZej-OU3"
      },
      "source": [
        "**offensive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uV421Xo4WOku"
      },
      "source": [
        "tweets_offensive = api.search('fag', count=20)\n",
        "tweets_offensive_2=api.search('skank', count=20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnGI_EaJ3VjN"
      },
      "source": [
        "offensive_tweet=[]\n",
        "for tweet in tweets_offensive:\n",
        "  offensive_tweet.append(tweet.text)\n",
        "offensive_tweet_2=[]\n",
        "for tweet in tweets_offensive_2:\n",
        "  offensive_tweet_2.append(tweet.text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RConKbOe3QGM"
      },
      "source": [
        "df_offensive_1=pd.DataFrame(offensive_tweet)\n",
        "df_offensive_2=pd.DataFrame(offensive_tweet_2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0mLfjJnBx1h"
      },
      "source": [
        "df_offensive_1['tweet']=df_offensive_1\n",
        "df_offensive_1['label']=1\n",
        "df_offensive_1=df_offensive_1[['tweet','label']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TyYin0TCNCO"
      },
      "source": [
        "df_offensive_2['tweet']=df_offensive_2\n",
        "df_offensive_2['label']=1\n",
        "df_offensive_2=df_offensive_2[['tweet','label']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mx1jf5jNCjBy"
      },
      "source": [
        "df_offensive=pd.concat([df_offensive_1,df_offensive_2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgPxhmiUDEkZ"
      },
      "source": [
        "**Hate**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dH4K1qq7Xh-E"
      },
      "source": [
        "tweets_hate = api.search('nigger', count=20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9o8d09W45tzS"
      },
      "source": [
        "hate_tweet=[]\n",
        "for tweet in tweets_hate:\n",
        "  hate_tweet.append(tweet.text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqV425E25t6O"
      },
      "source": [
        "df_hate=pd.DataFrame(hate_tweet)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oG3tChzd5uBz"
      },
      "source": [
        "df_hate['tweet']=df_hate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5s_hWXI46bbr"
      },
      "source": [
        "df_hate['label']=0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSCQWYjADrKG"
      },
      "source": [
        "df_hate=df_hate[['tweet','label']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zbdFPFbDZLX"
      },
      "source": [
        "df=pd.concat([df_hate,df_offensive,df_normal])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRcaLl8H_3By"
      },
      "source": [
        "df.to_csv('twitter.csv') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9w6AQSKqAh7H"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcgAuBIMWZ51"
      },
      "source": [
        "X=df['tweet']\n",
        "y=df['label']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xi1YkBkH__Qt"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWtKj3n-W1W3"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        " X, y, test_size=0.10, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "i-cQ-GxPWJMS",
        "outputId": "3f28defe-bdae-427d-98cf-99847016740d"
      },
      "source": [
        "with open('/content/model.pkl', 'rb') as file:\n",
        "    reg2 = pickle.load(file)\n",
        "reg2.predict(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnpicklingError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-d3240e985943>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/model.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mreg2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mreg2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnpicklingError\u001b[0m: invalid load key, 'v'."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdRAuYiNfU6x"
      },
      "source": [
        "knn_model_reloaded = pickle.load(open(filename, 'rb'))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}